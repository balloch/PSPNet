Log file created at: 2017/04/27 19:53:15
Running on machine: RAIL-HOTBOX
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0427 19:53:15.925209 20421 caffe.cpp:102] Use GPU with device ID 0
I0427 19:53:16.201715 20421 caffe.cpp:110] Starting Optimization
I0427 19:53:16.201799 20421 solver.cpp:32] Initializing solver from parameters: 
train_net: "exper/voc12/config/DeepLab-LargeFOV/train_train_aug.prototxt"
base_lr: 0.001
display: 10
max_iter: 6000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 2000
snapshot_prefix: "exper/voc12/model/DeepLab-LargeFOV/train"
solver_mode: GPU
I0427 19:53:16.201827 20421 solver.cpp:58] Creating training net from train_net file: exper/voc12/config/DeepLab-LargeFOV/train_train_aug.prototxt
I0427 19:53:16.202436 20421 net.cpp:39] Initializing net from parameters: 
name: "DeepLab-LargeFOV"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_SEG_DATA
  image_data_param {
    source: "exper/voc12/list/train_aug.txt"
    batch_size: 16
    shuffle: true
    root_folder: "exper/voc12/data"
    label_type: PIXEL
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 321
    mean_value: 104.008
    mean_value: 116.669
    mean_value: 122.675
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    hole: 2
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    hole: 2
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    hole: 2
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layers {
  bottom: "pool5"
  top: "pool5a"
  name: "pool5a"
  type: POOLING
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layers {
  bottom: "pool5a"
  top: "fc6"
  name: "fc6"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 1024
    pad: 12
    kernel_size: 3
    hole: 12
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_exper/voc12"
  name: "fc8_exper/voc12"
  type: CONVOLUTION
  blobs_lr: 10
  blobs_lr: 20
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "label"
  top: "label_shrink"
  name: "label_shrink"
  type: INTERP
  interp_param {
    shrink_factor: 8
    pad_beg: 0
    pad_end: 0
  }
}
layers {
  bottom: "fc8_exper/voc12"
  bottom: "label_shrink"
  name: "loss"
  type: SOFTMAX_LOSS
  include {
    phase: TRAIN
  }
  softmaxloss_param {
    ignore_label: 255
  }
}
layers {
  bottom: "fc8_exper/voc12"
  bottom: "label_shrink"
  top: "accuracy"
  name: "accuracy"
  type: SEG_ACCURACY
  seg_accuracy_param {
    ignore_label: 255
  }
}
state {
  phase: TRAIN
}
I0427 19:53:16.202656 20421 layer_factory.hpp:78] Creating layer data
I0427 19:53:16.202669 20421 net.cpp:67] Creating Layer data
I0427 19:53:16.202673 20421 net.cpp:356] data -> data
I0427 19:53:16.202682 20421 net.cpp:356] data -> label
I0427 19:53:16.202687 20421 net.cpp:356] data -> (automatic)
I0427 19:53:16.202690 20421 net.cpp:96] Setting up data
I0427 19:53:16.202693 20421 image_seg_data_layer.cpp:45] Opening file exper/voc12/list/train_aug.txt
I0427 19:53:16.209197 20421 image_seg_data_layer.cpp:62] Shuffling data
I0427 19:53:16.210494 20421 image_seg_data_layer.cpp:67] A total of 10582 images.
I0427 19:53:16.214684 20421 image_seg_data_layer.cpp:113] output data size: 16,3,321,321
I0427 19:53:16.214696 20421 image_seg_data_layer.cpp:117] output label size: 16,1,321,321
I0427 19:53:16.214699 20421 image_seg_data_layer.cpp:121] output data_dim size: 16,1,1,2
I0427 19:53:16.219022 20421 net.cpp:103] Top shape: 16 3 321 321 (4945968)
I0427 19:53:16.219065 20421 net.cpp:103] Top shape: 16 1 321 321 (1648656)
I0427 19:53:16.219074 20421 net.cpp:103] Top shape: 16 1 1 2 (32)
I0427 19:53:16.219080 20421 layer_factory.hpp:78] Creating layer conv1_1
I0427 19:53:16.219115 20421 net.cpp:67] Creating Layer conv1_1
I0427 19:53:16.219123 20421 net.cpp:394] conv1_1 <- data
I0427 19:53:16.219138 20421 net.cpp:356] conv1_1 -> conv1_1
I0427 19:53:16.219147 20421 net.cpp:96] Setting up conv1_1
I0427 19:53:16.219391 20421 net.cpp:103] Top shape: 16 64 321 321 (105513984)
I0427 19:53:16.219403 20421 layer_factory.hpp:78] Creating layer relu1_1
I0427 19:53:16.219410 20421 net.cpp:67] Creating Layer relu1_1
I0427 19:53:16.219413 20421 net.cpp:394] relu1_1 <- conv1_1
I0427 19:53:16.219418 20421 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I0427 19:53:16.219421 20421 net.cpp:96] Setting up relu1_1
I0427 19:53:16.219424 20421 net.cpp:103] Top shape: 16 64 321 321 (105513984)
I0427 19:53:16.219427 20421 layer_factory.hpp:78] Creating layer conv1_2
I0427 19:53:16.219431 20421 net.cpp:67] Creating Layer conv1_2
I0427 19:53:16.219434 20421 net.cpp:394] conv1_2 <- conv1_1
I0427 19:53:16.219437 20421 net.cpp:356] conv1_2 -> conv1_2
I0427 19:53:16.219441 20421 net.cpp:96] Setting up conv1_2
I0427 19:53:16.219681 20421 net.cpp:103] Top shape: 16 64 321 321 (105513984)
I0427 19:53:16.219688 20421 layer_factory.hpp:78] Creating layer relu1_2
I0427 19:53:16.219693 20421 net.cpp:67] Creating Layer relu1_2
I0427 19:53:16.219696 20421 net.cpp:394] relu1_2 <- conv1_2
I0427 19:53:16.219699 20421 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I0427 19:53:16.219703 20421 net.cpp:96] Setting up relu1_2
I0427 19:53:16.219707 20421 net.cpp:103] Top shape: 16 64 321 321 (105513984)
I0427 19:53:16.219709 20421 layer_factory.hpp:78] Creating layer pool1
I0427 19:53:16.219717 20421 net.cpp:67] Creating Layer pool1
I0427 19:53:16.219719 20421 net.cpp:394] pool1 <- conv1_2
I0427 19:53:16.219724 20421 net.cpp:356] pool1 -> pool1
I0427 19:53:16.219729 20421 net.cpp:96] Setting up pool1
I0427 19:53:16.219736 20421 net.cpp:103] Top shape: 16 64 161 161 (26543104)
I0427 19:53:16.219739 20421 layer_factory.hpp:78] Creating layer conv2_1
I0427 19:53:16.219743 20421 net.cpp:67] Creating Layer conv2_1
I0427 19:53:16.219745 20421 net.cpp:394] conv2_1 <- pool1
I0427 19:53:16.219749 20421 net.cpp:356] conv2_1 -> conv2_1
I0427 19:53:16.219753 20421 net.cpp:96] Setting up conv2_1
I0427 19:53:16.219923 20421 net.cpp:103] Top shape: 16 128 161 161 (53086208)
I0427 19:53:16.219929 20421 layer_factory.hpp:78] Creating layer relu2_1
I0427 19:53:16.219934 20421 net.cpp:67] Creating Layer relu2_1
I0427 19:53:16.219938 20421 net.cpp:394] relu2_1 <- conv2_1
I0427 19:53:16.219944 20421 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I0427 19:53:16.219947 20421 net.cpp:96] Setting up relu2_1
I0427 19:53:16.219951 20421 net.cpp:103] Top shape: 16 128 161 161 (53086208)
I0427 19:53:16.219954 20421 layer_factory.hpp:78] Creating layer conv2_2
I0427 19:53:16.219959 20421 net.cpp:67] Creating Layer conv2_2
I0427 19:53:16.219962 20421 net.cpp:394] conv2_2 <- conv2_1
I0427 19:53:16.219969 20421 net.cpp:356] conv2_2 -> conv2_2
I0427 19:53:16.219974 20421 net.cpp:96] Setting up conv2_2
I0427 19:53:16.220216 20421 net.cpp:103] Top shape: 16 128 161 161 (53086208)
I0427 19:53:16.220221 20421 layer_factory.hpp:78] Creating layer relu2_2
I0427 19:53:16.220227 20421 net.cpp:67] Creating Layer relu2_2
I0427 19:53:16.220229 20421 net.cpp:394] relu2_2 <- conv2_2
I0427 19:53:16.220233 20421 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I0427 19:53:16.220237 20421 net.cpp:96] Setting up relu2_2
I0427 19:53:16.220257 20421 net.cpp:103] Top shape: 16 128 161 161 (53086208)
I0427 19:53:16.220260 20421 layer_factory.hpp:78] Creating layer pool2
I0427 19:53:16.220264 20421 net.cpp:67] Creating Layer pool2
I0427 19:53:16.220268 20421 net.cpp:394] pool2 <- conv2_2
I0427 19:53:16.220273 20421 net.cpp:356] pool2 -> pool2
I0427 19:53:16.220278 20421 net.cpp:96] Setting up pool2
I0427 19:53:16.220283 20421 net.cpp:103] Top shape: 16 128 81 81 (13436928)
I0427 19:53:16.220285 20421 layer_factory.hpp:78] Creating layer conv3_1
I0427 19:53:16.220289 20421 net.cpp:67] Creating Layer conv3_1
I0427 19:53:16.220293 20421 net.cpp:394] conv3_1 <- pool2
I0427 19:53:16.220297 20421 net.cpp:356] conv3_1 -> conv3_1
I0427 19:53:16.220301 20421 net.cpp:96] Setting up conv3_1
I0427 19:53:16.220675 20421 net.cpp:103] Top shape: 16 256 81 81 (26873856)
I0427 19:53:16.220684 20421 layer_factory.hpp:78] Creating layer relu3_1
I0427 19:53:16.220687 20421 net.cpp:67] Creating Layer relu3_1
I0427 19:53:16.220690 20421 net.cpp:394] relu3_1 <- conv3_1
I0427 19:53:16.220695 20421 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I0427 19:53:16.220700 20421 net.cpp:96] Setting up relu3_1
I0427 19:53:16.220701 20421 net.cpp:103] Top shape: 16 256 81 81 (26873856)
I0427 19:53:16.220705 20421 layer_factory.hpp:78] Creating layer conv3_2
I0427 19:53:16.220710 20421 net.cpp:67] Creating Layer conv3_2
I0427 19:53:16.220713 20421 net.cpp:394] conv3_2 <- conv3_1
I0427 19:53:16.220717 20421 net.cpp:356] conv3_2 -> conv3_2
I0427 19:53:16.220721 20421 net.cpp:96] Setting up conv3_2
I0427 19:53:16.221588 20421 net.cpp:103] Top shape: 16 256 81 81 (26873856)
I0427 19:53:16.221601 20421 layer_factory.hpp:78] Creating layer relu3_2
I0427 19:53:16.221607 20421 net.cpp:67] Creating Layer relu3_2
I0427 19:53:16.221611 20421 net.cpp:394] relu3_2 <- conv3_2
I0427 19:53:16.221617 20421 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I0427 19:53:16.221622 20421 net.cpp:96] Setting up relu3_2
I0427 19:53:16.221626 20421 net.cpp:103] Top shape: 16 256 81 81 (26873856)
I0427 19:53:16.221628 20421 layer_factory.hpp:78] Creating layer conv3_3
I0427 19:53:16.221633 20421 net.cpp:67] Creating Layer conv3_3
I0427 19:53:16.221635 20421 net.cpp:394] conv3_3 <- conv3_2
I0427 19:53:16.221640 20421 net.cpp:356] conv3_3 -> conv3_3
I0427 19:53:16.221644 20421 net.cpp:96] Setting up conv3_3
I0427 19:53:16.222267 20421 net.cpp:103] Top shape: 16 256 81 81 (26873856)
I0427 19:53:16.222273 20421 layer_factory.hpp:78] Creating layer relu3_3
I0427 19:53:16.222281 20421 net.cpp:67] Creating Layer relu3_3
I0427 19:53:16.222285 20421 net.cpp:394] relu3_3 <- conv3_3
I0427 19:53:16.222290 20421 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I0427 19:53:16.222293 20421 net.cpp:96] Setting up relu3_3
I0427 19:53:16.222296 20421 net.cpp:103] Top shape: 16 256 81 81 (26873856)
I0427 19:53:16.222299 20421 layer_factory.hpp:78] Creating layer pool3
I0427 19:53:16.222304 20421 net.cpp:67] Creating Layer pool3
I0427 19:53:16.222307 20421 net.cpp:394] pool3 <- conv3_3
I0427 19:53:16.222312 20421 net.cpp:356] pool3 -> pool3
I0427 19:53:16.222317 20421 net.cpp:96] Setting up pool3
I0427 19:53:16.222322 20421 net.cpp:103] Top shape: 16 256 41 41 (6885376)
I0427 19:53:16.222326 20421 layer_factory.hpp:78] Creating layer conv4_1
I0427 19:53:16.222331 20421 net.cpp:67] Creating Layer conv4_1
I0427 19:53:16.222332 20421 net.cpp:394] conv4_1 <- pool3
I0427 19:53:16.222337 20421 net.cpp:356] conv4_1 -> conv4_1
I0427 19:53:16.222342 20421 net.cpp:96] Setting up conv4_1
I0427 19:53:16.223610 20421 net.cpp:103] Top shape: 16 512 41 41 (13770752)
I0427 19:53:16.223634 20421 layer_factory.hpp:78] Creating layer relu4_1
I0427 19:53:16.223642 20421 net.cpp:67] Creating Layer relu4_1
I0427 19:53:16.223647 20421 net.cpp:394] relu4_1 <- conv4_1
I0427 19:53:16.223654 20421 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I0427 19:53:16.223657 20421 net.cpp:96] Setting up relu4_1
I0427 19:53:16.223661 20421 net.cpp:103] Top shape: 16 512 41 41 (13770752)
I0427 19:53:16.223664 20421 layer_factory.hpp:78] Creating layer conv4_2
I0427 19:53:16.223670 20421 net.cpp:67] Creating Layer conv4_2
I0427 19:53:16.223695 20421 net.cpp:394] conv4_2 <- conv4_1
I0427 19:53:16.223701 20421 net.cpp:356] conv4_2 -> conv4_2
I0427 19:53:16.223708 20421 net.cpp:96] Setting up conv4_2
I0427 19:53:16.228036 20421 net.cpp:103] Top shape: 16 512 41 41 (13770752)
I0427 19:53:16.228086 20421 layer_factory.hpp:78] Creating layer relu4_2
I0427 19:53:16.228102 20421 net.cpp:67] Creating Layer relu4_2
I0427 19:53:16.228111 20421 net.cpp:394] relu4_2 <- conv4_2
I0427 19:53:16.228118 20421 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I0427 19:53:16.228126 20421 net.cpp:96] Setting up relu4_2
I0427 19:53:16.228130 20421 net.cpp:103] Top shape: 16 512 41 41 (13770752)
I0427 19:53:16.228133 20421 layer_factory.hpp:78] Creating layer conv4_3
I0427 19:53:16.228142 20421 net.cpp:67] Creating Layer conv4_3
I0427 19:53:16.228145 20421 net.cpp:394] conv4_3 <- conv4_2
I0427 19:53:16.228149 20421 net.cpp:356] conv4_3 -> conv4_3
I0427 19:53:16.228155 20421 net.cpp:96] Setting up conv4_3
I0427 19:53:16.231947 20421 net.cpp:103] Top shape: 16 512 41 41 (13770752)
I0427 19:53:16.232014 20421 layer_factory.hpp:78] Creating layer relu4_3
I0427 19:53:16.232038 20421 net.cpp:67] Creating Layer relu4_3
I0427 19:53:16.232045 20421 net.cpp:394] relu4_3 <- conv4_3
I0427 19:53:16.232058 20421 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I0427 19:53:16.232071 20421 net.cpp:96] Setting up relu4_3
I0427 19:53:16.232077 20421 net.cpp:103] Top shape: 16 512 41 41 (13770752)
I0427 19:53:16.232080 20421 layer_factory.hpp:78] Creating layer pool4
I0427 19:53:16.232091 20421 net.cpp:67] Creating Layer pool4
I0427 19:53:16.232095 20421 net.cpp:394] pool4 <- conv4_3
I0427 19:53:16.232102 20421 net.cpp:356] pool4 -> pool4
I0427 19:53:16.232117 20421 net.cpp:96] Setting up pool4
I0427 19:53:16.232128 20421 net.cpp:103] Top shape: 16 512 41 41 (13770752)
I0427 19:53:16.232131 20421 layer_factory.hpp:78] Creating layer conv5_1
I0427 19:53:16.232141 20421 net.cpp:67] Creating Layer conv5_1
I0427 19:53:16.232142 20421 net.cpp:394] conv5_1 <- pool4
I0427 19:53:16.232162 20421 net.cpp:356] conv5_1 -> conv5_1
I0427 19:53:16.232169 20421 net.cpp:96] Setting up conv5_1
I0427 19:53:16.238023 20421 net.cpp:103] Top shape: 16 512 41 41 (13770752)
I0427 19:53:16.238085 20421 layer_factory.hpp:78] Creating layer relu5_1
I0427 19:53:16.238101 20421 net.cpp:67] Creating Layer relu5_1
I0427 19:53:16.238111 20421 net.cpp:394] relu5_1 <- conv5_1
I0427 19:53:16.238121 20421 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I0427 19:53:16.238132 20421 net.cpp:96] Setting up relu5_1
I0427 19:53:16.238137 20421 net.cpp:103] Top shape: 16 512 41 41 (13770752)
I0427 19:53:16.238140 20421 layer_factory.hpp:78] Creating layer conv5_2
I0427 19:53:16.238152 20421 net.cpp:67] Creating Layer conv5_2
I0427 19:53:16.238154 20421 net.cpp:394] conv5_2 <- conv5_1
I0427 19:53:16.238178 20421 net.cpp:356] conv5_2 -> conv5_2
I0427 19:53:16.238185 20421 net.cpp:96] Setting up conv5_2
I0427 19:53:16.241559 20421 net.cpp:103] Top shape: 16 512 41 41 (13770752)
I0427 19:53:16.241583 20421 layer_factory.hpp:78] Creating layer relu5_2
I0427 19:53:16.241591 20421 net.cpp:67] Creating Layer relu5_2
I0427 19:53:16.241595 20421 net.cpp:394] relu5_2 <- conv5_2
I0427 19:53:16.241600 20421 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I0427 19:53:16.241611 20421 net.cpp:96] Setting up relu5_2
I0427 19:53:16.241614 20421 net.cpp:103] Top shape: 16 512 41 41 (13770752)
I0427 19:53:16.241618 20421 layer_factory.hpp:78] Creating layer conv5_3
I0427 19:53:16.241628 20421 net.cpp:67] Creating Layer conv5_3
I0427 19:53:16.241631 20421 net.cpp:394] conv5_3 <- conv5_2
I0427 19:53:16.241636 20421 net.cpp:356] conv5_3 -> conv5_3
I0427 19:53:16.241642 20421 net.cpp:96] Setting up conv5_3
I0427 19:53:16.244700 20421 net.cpp:103] Top shape: 16 512 41 41 (13770752)
I0427 19:53:16.244732 20421 layer_factory.hpp:78] Creating layer relu5_3
I0427 19:53:16.244741 20421 net.cpp:67] Creating Layer relu5_3
I0427 19:53:16.244745 20421 net.cpp:394] relu5_3 <- conv5_3
I0427 19:53:16.244753 20421 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I0427 19:53:16.244783 20421 net.cpp:96] Setting up relu5_3
I0427 19:53:16.244787 20421 net.cpp:103] Top shape: 16 512 41 41 (13770752)
I0427 19:53:16.244791 20421 layer_factory.hpp:78] Creating layer pool5
I0427 19:53:16.244798 20421 net.cpp:67] Creating Layer pool5
I0427 19:53:16.244802 20421 net.cpp:394] pool5 <- conv5_3
I0427 19:53:16.244807 20421 net.cpp:356] pool5 -> pool5
I0427 19:53:16.244812 20421 net.cpp:96] Setting up pool5
I0427 19:53:16.244819 20421 net.cpp:103] Top shape: 16 512 41 41 (13770752)
I0427 19:53:16.244822 20421 layer_factory.hpp:78] Creating layer pool5a
I0427 19:53:16.244835 20421 net.cpp:67] Creating Layer pool5a
I0427 19:53:16.244838 20421 net.cpp:394] pool5a <- pool5
I0427 19:53:16.244841 20421 net.cpp:356] pool5a -> pool5a
I0427 19:53:16.244846 20421 net.cpp:96] Setting up pool5a
I0427 19:53:16.244849 20421 net.cpp:103] Top shape: 16 512 41 41 (13770752)
I0427 19:53:16.244853 20421 layer_factory.hpp:78] Creating layer fc6
I0427 19:53:16.244858 20421 net.cpp:67] Creating Layer fc6
I0427 19:53:16.244863 20421 net.cpp:394] fc6 <- pool5a
I0427 19:53:16.244868 20421 net.cpp:356] fc6 -> fc6
I0427 19:53:16.244873 20421 net.cpp:96] Setting up fc6
I0427 19:53:16.251307 20421 net.cpp:103] Top shape: 16 1024 41 41 (27541504)
I0427 19:53:16.251334 20421 layer_factory.hpp:78] Creating layer relu6
I0427 19:53:16.251344 20421 net.cpp:67] Creating Layer relu6
I0427 19:53:16.251349 20421 net.cpp:394] relu6 <- fc6
I0427 19:53:16.251355 20421 net.cpp:345] relu6 -> fc6 (in-place)
I0427 19:53:16.251363 20421 net.cpp:96] Setting up relu6
I0427 19:53:16.251368 20421 net.cpp:103] Top shape: 16 1024 41 41 (27541504)
I0427 19:53:16.251370 20421 layer_factory.hpp:78] Creating layer drop6
I0427 19:53:16.251380 20421 net.cpp:67] Creating Layer drop6
I0427 19:53:16.251384 20421 net.cpp:394] drop6 <- fc6
I0427 19:53:16.251389 20421 net.cpp:345] drop6 -> fc6 (in-place)
I0427 19:53:16.251394 20421 net.cpp:96] Setting up drop6
I0427 19:53:16.251399 20421 net.cpp:103] Top shape: 16 1024 41 41 (27541504)
I0427 19:53:16.251402 20421 layer_factory.hpp:78] Creating layer fc7
I0427 19:53:16.251410 20421 net.cpp:67] Creating Layer fc7
I0427 19:53:16.251413 20421 net.cpp:394] fc7 <- fc6
I0427 19:53:16.251418 20421 net.cpp:356] fc7 -> fc7
I0427 19:53:16.251425 20421 net.cpp:96] Setting up fc7
I0427 19:53:16.252729 20421 net.cpp:103] Top shape: 16 1024 41 41 (27541504)
I0427 19:53:16.252744 20421 layer_factory.hpp:78] Creating layer relu7
I0427 19:53:16.252750 20421 net.cpp:67] Creating Layer relu7
I0427 19:53:16.252754 20421 net.cpp:394] relu7 <- fc7
I0427 19:53:16.252760 20421 net.cpp:345] relu7 -> fc7 (in-place)
I0427 19:53:16.252765 20421 net.cpp:96] Setting up relu7
I0427 19:53:16.252769 20421 net.cpp:103] Top shape: 16 1024 41 41 (27541504)
I0427 19:53:16.252774 20421 layer_factory.hpp:78] Creating layer drop7
I0427 19:53:16.252779 20421 net.cpp:67] Creating Layer drop7
I0427 19:53:16.252782 20421 net.cpp:394] drop7 <- fc7
I0427 19:53:16.252786 20421 net.cpp:345] drop7 -> fc7 (in-place)
I0427 19:53:16.252791 20421 net.cpp:96] Setting up drop7
I0427 19:53:16.252795 20421 net.cpp:103] Top shape: 16 1024 41 41 (27541504)
I0427 19:53:16.252799 20421 layer_factory.hpp:78] Creating layer fc8_exper/voc12
I0427 19:53:16.252806 20421 net.cpp:67] Creating Layer fc8_exper/voc12
I0427 19:53:16.252810 20421 net.cpp:394] fc8_exper/voc12 <- fc7
I0427 19:53:16.252815 20421 net.cpp:356] fc8_exper/voc12 -> fc8_exper/voc12
I0427 19:53:16.252820 20421 net.cpp:96] Setting up fc8_exper/voc12
I0427 19:53:16.253450 20421 net.cpp:103] Top shape: 16 21 41 41 (564816)
I0427 19:53:16.253461 20421 layer_factory.hpp:78] Creating layer fc8_exper/voc12_fc8_exper/voc12_0_split
I0427 19:53:16.253473 20421 net.cpp:67] Creating Layer fc8_exper/voc12_fc8_exper/voc12_0_split
I0427 19:53:16.253479 20421 net.cpp:394] fc8_exper/voc12_fc8_exper/voc12_0_split <- fc8_exper/voc12
I0427 19:53:16.253484 20421 net.cpp:356] fc8_exper/voc12_fc8_exper/voc12_0_split -> fc8_exper/voc12_fc8_exper/voc12_0_split_0
I0427 19:53:16.253490 20421 net.cpp:356] fc8_exper/voc12_fc8_exper/voc12_0_split -> fc8_exper/voc12_fc8_exper/voc12_0_split_1
I0427 19:53:16.253512 20421 net.cpp:96] Setting up fc8_exper/voc12_fc8_exper/voc12_0_split
I0427 19:53:16.253521 20421 net.cpp:103] Top shape: 16 21 41 41 (564816)
I0427 19:53:16.253525 20421 net.cpp:103] Top shape: 16 21 41 41 (564816)
I0427 19:53:16.253528 20421 layer_factory.hpp:78] Creating layer label_shrink
I0427 19:53:16.253535 20421 net.cpp:67] Creating Layer label_shrink
I0427 19:53:16.253538 20421 net.cpp:394] label_shrink <- label
I0427 19:53:16.253545 20421 net.cpp:356] label_shrink -> label_shrink
I0427 19:53:16.253551 20421 net.cpp:96] Setting up label_shrink
I0427 19:53:16.253554 20421 net.cpp:103] Top shape: 16 1 41 41 (26896)
I0427 19:53:16.253558 20421 layer_factory.hpp:78] Creating layer label_shrink_label_shrink_0_split
I0427 19:53:16.253562 20421 net.cpp:67] Creating Layer label_shrink_label_shrink_0_split
I0427 19:53:16.253566 20421 net.cpp:394] label_shrink_label_shrink_0_split <- label_shrink
I0427 19:53:16.253571 20421 net.cpp:356] label_shrink_label_shrink_0_split -> label_shrink_label_shrink_0_split_0
I0427 19:53:16.253577 20421 net.cpp:356] label_shrink_label_shrink_0_split -> label_shrink_label_shrink_0_split_1
I0427 19:53:16.253582 20421 net.cpp:96] Setting up label_shrink_label_shrink_0_split
I0427 19:53:16.253587 20421 net.cpp:103] Top shape: 16 1 41 41 (26896)
I0427 19:53:16.253590 20421 net.cpp:103] Top shape: 16 1 41 41 (26896)
I0427 19:53:16.253594 20421 layer_factory.hpp:78] Creating layer loss
I0427 19:53:16.253602 20421 net.cpp:67] Creating Layer loss
I0427 19:53:16.253607 20421 net.cpp:394] loss <- fc8_exper/voc12_fc8_exper/voc12_0_split_0
I0427 19:53:16.253610 20421 net.cpp:394] loss <- label_shrink_label_shrink_0_split_0
I0427 19:53:16.253617 20421 net.cpp:356] loss -> (automatic)
I0427 19:53:16.253621 20421 net.cpp:96] Setting up loss
I0427 19:53:16.253630 20421 softmax_loss_layer.cpp:40] Weight_Loss file is not provided. Assign all one to it.
I0427 19:53:16.253636 20421 net.cpp:103] Top shape: 1 1 1 1 (1)
I0427 19:53:16.253640 20421 net.cpp:109]     with loss weight 1
I0427 19:53:16.253672 20421 layer_factory.hpp:78] Creating layer accuracy
I0427 19:53:16.253679 20421 net.cpp:67] Creating Layer accuracy
I0427 19:53:16.253684 20421 net.cpp:394] accuracy <- fc8_exper/voc12_fc8_exper/voc12_0_split_1
I0427 19:53:16.253687 20421 net.cpp:394] accuracy <- label_shrink_label_shrink_0_split_1
I0427 19:53:16.253693 20421 net.cpp:356] accuracy -> accuracy
I0427 19:53:16.253697 20421 net.cpp:96] Setting up accuracy
I0427 19:53:16.253707 20421 net.cpp:103] Top shape: 1 1 1 3 (3)
I0427 19:53:16.253710 20421 net.cpp:172] accuracy does not need backward computation.
I0427 19:53:16.253715 20421 net.cpp:170] loss needs backward computation.
I0427 19:53:16.253718 20421 net.cpp:172] label_shrink_label_shrink_0_split does not need backward computation.
I0427 19:53:16.253722 20421 net.cpp:172] label_shrink does not need backward computation.
I0427 19:53:16.253726 20421 net.cpp:170] fc8_exper/voc12_fc8_exper/voc12_0_split needs backward computation.
I0427 19:53:16.253729 20421 net.cpp:170] fc8_exper/voc12 needs backward computation.
I0427 19:53:16.253733 20421 net.cpp:170] drop7 needs backward computation.
I0427 19:53:16.253736 20421 net.cpp:170] relu7 needs backward computation.
I0427 19:53:16.253739 20421 net.cpp:170] fc7 needs backward computation.
I0427 19:53:16.253743 20421 net.cpp:170] drop6 needs backward computation.
I0427 19:53:16.253747 20421 net.cpp:170] relu6 needs backward computation.
I0427 19:53:16.253751 20421 net.cpp:170] fc6 needs backward computation.
I0427 19:53:16.253754 20421 net.cpp:170] pool5a needs backward computation.
I0427 19:53:16.253759 20421 net.cpp:170] pool5 needs backward computation.
I0427 19:53:16.253763 20421 net.cpp:170] relu5_3 needs backward computation.
I0427 19:53:16.253767 20421 net.cpp:170] conv5_3 needs backward computation.
I0427 19:53:16.253770 20421 net.cpp:170] relu5_2 needs backward computation.
I0427 19:53:16.253774 20421 net.cpp:170] conv5_2 needs backward computation.
I0427 19:53:16.253784 20421 net.cpp:170] relu5_1 needs backward computation.
I0427 19:53:16.253788 20421 net.cpp:170] conv5_1 needs backward computation.
I0427 19:53:16.253793 20421 net.cpp:170] pool4 needs backward computation.
I0427 19:53:16.253796 20421 net.cpp:170] relu4_3 needs backward computation.
I0427 19:53:16.253800 20421 net.cpp:170] conv4_3 needs backward computation.
I0427 19:53:16.253804 20421 net.cpp:170] relu4_2 needs backward computation.
I0427 19:53:16.253808 20421 net.cpp:170] conv4_2 needs backward computation.
I0427 19:53:16.253813 20421 net.cpp:170] relu4_1 needs backward computation.
I0427 19:53:16.253815 20421 net.cpp:170] conv4_1 needs backward computation.
I0427 19:53:16.253819 20421 net.cpp:170] pool3 needs backward computation.
I0427 19:53:16.253823 20421 net.cpp:170] relu3_3 needs backward computation.
I0427 19:53:16.253828 20421 net.cpp:170] conv3_3 needs backward computation.
I0427 19:53:16.253831 20421 net.cpp:170] relu3_2 needs backward computation.
I0427 19:53:16.253835 20421 net.cpp:170] conv3_2 needs backward computation.
I0427 19:53:16.253839 20421 net.cpp:170] relu3_1 needs backward computation.
I0427 19:53:16.253842 20421 net.cpp:170] conv3_1 needs backward computation.
I0427 19:53:16.253845 20421 net.cpp:170] pool2 needs backward computation.
I0427 19:53:16.253850 20421 net.cpp:170] relu2_2 needs backward computation.
I0427 19:53:16.253854 20421 net.cpp:170] conv2_2 needs backward computation.
I0427 19:53:16.253859 20421 net.cpp:170] relu2_1 needs backward computation.
I0427 19:53:16.253861 20421 net.cpp:170] conv2_1 needs backward computation.
I0427 19:53:16.253865 20421 net.cpp:170] pool1 needs backward computation.
I0427 19:53:16.253870 20421 net.cpp:170] relu1_2 needs backward computation.
I0427 19:53:16.253873 20421 net.cpp:170] conv1_2 needs backward computation.
I0427 19:53:16.253876 20421 net.cpp:170] relu1_1 needs backward computation.
I0427 19:53:16.253880 20421 net.cpp:170] conv1_1 needs backward computation.
I0427 19:53:16.253885 20421 net.cpp:172] data does not need backward computation.
I0427 19:53:16.253887 20421 net.cpp:208] This network produces output accuracy
I0427 19:53:16.253912 20421 net.cpp:467] Collecting Learning Rate and Weight Decay.
I0427 19:53:16.253922 20421 net.cpp:219] Network initialization done.
I0427 19:53:16.253926 20421 net.cpp:220] Memory required for data: 4890757648
I0427 19:53:16.253998 20421 solver.cpp:41] Solver scaffolding done.
I0427 19:53:16.254001 20421 caffe.cpp:118] Finetuning from exper/voc12/model/DeepLab-LargeFOV/init.caffemodel
I0427 19:53:16.473734 20421 net.cpp:740] Target layer fc8_exper/voc12 not initialized.
I0427 19:53:16.474062 20421 solver.cpp:160] Solving DeepLab-LargeFOV
I0427 19:53:16.474068 20421 solver.cpp:161] Learning Rate Policy: step
F0427 19:53:17.548004 20421 syncedmem.cpp:51] Check failed: error == cudaSuccess (2 vs. 0)  out of memory
